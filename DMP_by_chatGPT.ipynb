{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f5e169-ca07-427e-bb71-97276a48d2ae",
   "metadata": {},
   "source": [
    "# Writing project-specific Data Management Plans using chatGPT\n",
    "In this notebook I will use the [OpenAI API](https://openai.com/blog/openai-api) and chatGPT 4.0 to turn a fictive project description and a skeleton for a Data Management Plan (DMP) into a project-specifici DMP. If you want to rerun this notebook, you need an OpenAI API key, and execution of the notebook may cost money."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b93d13e-d891-4b42-8f1e-eb72114bb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35bfce6-0947-4636-97ee-25b60f02e6d2",
   "metadata": {},
   "source": [
    "We define some helper-function to send a prompt to chatGPT and retrieve the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6ecc39-15bf-4718-a88b-3a5e2f706e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(message:str, model=\"gpt-4\"):\n",
    "    \"\"\"A prompt helper function that sends a message to openAI\n",
    "    and prints the response using Markdown\n",
    "    \"\"\"   \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48041f02-04d5-427c-a951-8812c3b79dc0",
   "metadata": {},
   "source": [
    "## Asking chatGPT about DMPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1eb16e-c77c-4d47-87d4-51442a24b61d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Introduction / Overview\n",
       "2. Types of Data to be Collected or Created\n",
       "3. Data Collection Methods\n",
       "4. Data Backup and Security \n",
       "5. Data Documentation and Metadata \n",
       "6. Ethical Issues and Confidentiality\n",
       "7. Data Storage and Preservation \n",
       "8. Data Sharing and Access \n",
       "9. Data Reuse and Distribution \n",
       "10. Roles and Responsibilities \n",
       "11. Data Quality Assurance and Control\n",
       "12. Budget and Resources \n",
       "13. Data Retention and Disposal  \n",
       "14. Review and Update of the Data Management Plan"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = prompt(\"\"\"\n",
    "Give me a short list of typical sections of a Data Management Plan. \n",
    "Write bullet points and no detailed explanation.\n",
    "\"\"\")\n",
    "\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d07631d-fac2-485e-8d5b-b2a3f2717e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The \"Backup and Archiving\" section in a Data Management Plan typically describes the strategies and procedures for regularly backing up data to prevent loss due to unforeseen circumstances, including details on the frequency of backups, backup locations, and data recovery processes. It also outlines the plans for long-term preservation and archiving of data, often specifying the archiving duration, formats to be used, and strategies for data migration to overcome technology obsolescence. Relevant aspects such as security measures, access controls, and responsibility assignations for both backup and archiving processes are also elucidated."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = prompt(\"\"\"\n",
    "What is commonly described in a section about \"Backup and Archiving\" in a \n",
    "Data Management Plan? Answer in 3 sentences.\n",
    "\"\"\")\n",
    "\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f3a16c-b730-4192-9d03-83f3f56d0054",
   "metadata": {},
   "source": [
    "## Our project description\n",
    "In the following cell you find a description of a fictive project. It contains all aspects of such a project that came to my mind when I though of the aspects chatGPT mentioned above. It is structured chronologously, listing things that happen early in the project first, and transitioning towards publication of a manuscript, code and data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1e63667-400f-40ef-8e91-cba88abdc629",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_description = \"\"\"\n",
    "In our project we investigate the underlying physical principles for Gastrulation \n",
    "in Tribolium castaneum embryo development. Therefore, we use light-sheet microscopes\n",
    "to acquire 3D timelapse imaging data. We store this data in the NGFF file format. \n",
    "After acquistion, two scientists, typically a PhD student and a post-doc or \n",
    "group leader look into the data together and decide if the dataset will be analyzed \n",
    "in detail. In case yes, we upload the data to an Omero-Server, a research data \n",
    "management solution specifically developed for microscopy imaging data. Data on \n",
    "this server is automatically backed-up by the compute center of our university. We then login \n",
    "to the Jupyter Lab server of the institute where we analyze the data. Analysis results\n",
    "are also stored in the Omero-Server next to the imaging data results belong to. The\n",
    "Python analysis code we write is stored in the institutional git-server. Also this \n",
    "server is backed up by the compute center. When the project advances, we start writing\n",
    "a manuscipt using overleaf, an online service for collaborative manuscipt editing \n",
    "based on latex files. After every writing session, we save back the changed manuscript \n",
    "to the institutional git server. As soon as the manuscript is finished and \n",
    "submitted to the bioRxiv, a preprint server in the life-sciences, we also publish the \n",
    "project-related code by marking the project on the git-server as public. We also\n",
    "tag the code with a release version. At the same time we publish the imaging data \n",
    "by submitting a copy of the dataset from the Omero-Server to zenodo.org, a \n",
    "community-driven repository for research data funded by the European Union. Another \n",
    "copy of the data, the code and the manuscript is stored on the institutional archive \n",
    "server. This server, maintained by the compute center, garantees to archive data for \n",
    "15 years. Documents and data we published is licensed under CC-BY 4.0 license. The code \n",
    "we publish is licensed BSD3. The entire project and all steps of the data life-cycle \n",
    "are documented in an institutional labnotebook where every user has to pay 10 Euro \n",
    "per month. Four people will work on the project. The compute center estimates the \n",
    "costs for storage and maintenance of the infrastructure to 20k Euro and half a \n",
    "position of an IT specialist. The project duration is four years.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a0742c-28b1-44c9-8d7e-64ac0d91d7fc",
   "metadata": {},
   "source": [
    "We can then use this project description as part of a prompt to chatGPT to turn this unstructured text into a DMP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fa8696-4fc2-4bde-a459-71a4a6cb7661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data Management Plan for Investigation of Gastrulation in Tribolium Castaneum Embryo Development\n",
       "\n",
       "1. Data Collection: Data is procured through the use of light-sheet microscopes, which produces 3D timelapse imaging data, archived in the NGFF file format. The data review is performed by a minimum of two researchers, following which a decision on detailed data analysis is made.\n",
       "\n",
       "2. Data Storage: If the data is chosen for further analysis, it is uploaded to an Omero-Server, a platform specifically designed for microscope imaging data management. The platform is backed up by the university's compute center, ensuring the data's security. Analysis results are stored alongside the original data for easy access and reference.\n",
       "\n",
       "3. Data Processing: Data processing is carried out on the institute's Jupyter Lab server. Python is used to code the analysis, which is then stored on the institutional git-server, offering another level of data backup.\n",
       "\n",
       "4. Documentation: The team documents every stage of the project in an institutional lab notebook. The manuscript drafting is conducted via Overleaf, an online collaborative tool, with every version being saved back into the institutional git-server.\n",
       "\n",
       "5. Data Availability: When complete, manuscripts are submitted to bioRxiv, a preprint server in life sciences. The code relative to the project is made public on the git-server and tagged with a release version. Imaging data is submitted to zenodo.org, a EU-funded research data repository. Additionally, a complete copy of project materials is stored on the institutional archive server for a guaranteed period of 15 years.\n",
       "\n",
       "6. Licensing: All published documents and data fall under the CC-BY 4.0 license, while the published code is licensed BSD3.\n",
       "\n",
       "7. Personnel: A team of four is assigned to the project. The university's compute center also dedicates half an IT specialistâ€™s role to this project for maintenance and support.\n",
       "\n",
       "8. Costs: Estimated costs for storage and infrastructure maintenance are roughly 20,000 Euros, with an expected project duration of four years.\n",
       "\n",
       "9. Compliance: All team members are required to adhere to the guidelines set within this data management plan.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = prompt(f\"\"\"\n",
    "You are a professional grant proposal writer. In the following comes a description of \n",
    "a common project in our \"Tribolium Development\" Research Group at the University. \n",
    "Your task is to reformulate this project description into a Data Management Plan.\n",
    "\n",
    "{project_description}\n",
    "\"\"\")\n",
    "\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a587f9-4136-4cda-9845-3d22e69ea6a7",
   "metadata": {},
   "source": [
    "## Combining information and structure\n",
    "We next modify the prompt to also add information about the structure we need. This structure may be different from funding agency to funding agency and thus, this step is crucial in customizing the DMP accoring to given formal requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c14e17c-8a1e-40a5-8123-ea5e4aa4dc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Data Management Plan\n",
       "\n",
       "## Data Description\n",
       "Our study aims at understanding the fundamental physical principles informing Gastrulation in Tribolium castaneum embryo development. Through this endeavor, we will generate 3D timelapse imaging data gathered from light-sheet microscopes. The data sets are stored using the NGFF file format. In the process of the project, we will create Python-based code for data analysis, research papers drafted on Overleaf, which incorporates the findings and results of our study.\n",
       "\n",
       "## Documentation and Data Quality\n",
       "Once the required data is acquired, it undergoes a scrutiny process where two scientists, generally a post-doc or group leader along with a PhD scholar, determine whether the data merits a detailed analysis. If affirmed, it will be stored on our Omero-Server - an exclusive data management solution created for microscopy imaging data. The analysis results, Python analysis scripts, and manuscript edits are also stored in this server and always updated after each modification.\n",
       "\n",
       "## Storage and Technical Archiving of the Project\n",
       "The data on the Omero-Server and the institutional git-server, where we store the Python analysis code and edits to our manuscript, are automatically backed up by our university's compute center. Completed aspects of the project are retained in the institutional archive server for a guaranteed period of 15 years. This archive likewise holds a copy of all published data, code, and manuscripts attached to the project.\n",
       "\n",
       "## Legal Obligations and Conditions\n",
       "Our published documents and data are licensed under the CC-BY 4.0 license, while the published code follows the BSD3 license. Individuals working on the project and accessing the institutional lab notebook are required to pay a monthly fee of 10 Euros.\n",
       "\n",
       "## Data Exchange and Long-term Data Accessibility\n",
       "To ensure wider accessibility and visibility, we publish our finalized manuscripts to the bioRxiv - a preprint server primarily geared towards the life-sciences. We further open-source our project-related Python code by switching the settings on our git-server to public and tagging the code with a release version. All imaging data will be made accessible by uploading a copy of the data set from the Omero-Server to zenodo.org - a community-driven repository for research data backed by the European Union.\n",
       "\n",
       "## Responsibilities and Resources\n",
       "The research group comprises four members who will be actively involved in the project that spans over four years. The compute center estimates the infrastructural costs for both storage and maintenance to be 20k Euros and one-half of an IT specialist's position."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = prompt(f\"\"\"\n",
    "You are a professional grant proposal writer. In the following comes a description of \n",
    "a common project in our \"Tribolium Development\" Research Group at the University. \n",
    "Your task is to reformulate this project description into a Data Management Plan.\n",
    "\n",
    "{project_description}\n",
    "\n",
    "The required structure for the data management plan, we need to write is like this:\n",
    "\n",
    "# Data Management Plan\n",
    "## Data description\n",
    "## Documentation and data quality\n",
    "## Storage and technical archiving the project\n",
    "## Legal obligations and conditions \n",
    "## Data exchange and long-term data accessibility\n",
    "## Responsibilities and resources\n",
    "\n",
    "Use Markdown for headlines and text style.\n",
    "\"\"\")\n",
    "\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9df21-873a-4fb5-ab98-f7fb65a1c814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
